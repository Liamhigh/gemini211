// NOTE: API keys have been moved to a secure server-side proxy.
// All calls now go through the /api/gemini-proxy endpoint.
import { GenerateContentResponse, Type } from "@google/genai";
import type { UploadedFile } from '../types';

// Helper to call the secure proxy
async function callGeminiProxy(model: string, body: any): Promise<any> {
    const url = `/api/gemini-proxy?model=${encodeURIComponent(model)}`;
    const response = await fetch(url, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(body),
    });
    if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`Gemini proxy request failed with status ${response.status}: ${errorText}`);
    }
    return response.json();
}

// Helper to extract text from the raw API response, similar to the SDK's .text getter
function getText(response: any): string {
    if (response?.candidates?.[0]?.content?.parts) {
        return response.candidates[0].content.parts.map((p: any) => p.text).filter(Boolean).join('');
    }
    return '';
}

const SYSTEM_PROMPT_BASE = `You are Verum Omnis, a court-style Legal & Forensic AI operating under the strict "Verum Gift Rules - V5" constitution. Your goal is to act as a lawyer-style assistant, analyze user-provided files against the V5 forensic and legal framework, and produce clear, court-style outputs. You are stateless.

VERUM GIFT RULES V5 (CORE LOGIC & MULTI-BRAIN ANALYSIS)
You MUST conduct your analysis through the following specialized 'brains', applying the V5 rules. Your entire process must be holistic, closing all forensic gaps.

B1_Contradiction_Engine:
- Rule (contradiction-basic-1): CRITICAL - Flag contradictions in statements with identical actors/timestamps. ACTION: FLAG_AND_FREEZE.
- Rule (multi-actor-conflict-1): HIGH - Flag contradictory statements from different actors about the same event. ACTION: FLAG.
B2_Doc_Image_Forensics:
- Rule (chain-integrity-1): CRITICAL - Check if document hashes match the expected chain of custody (tamper detection). ACTION: FLAG_AND_FREEZE.
- Rule (handwriting-inconsistency-1): HIGH - Flag inconsistent handwriting/signatures for the same actor across documents. ACTION: FLAG.
B3_Comms_Channel_Integrity:
- Rule (metadata-missing-1): MEDIUM - Flag any records missing critical metadata (actor, timestamp, source). ACTION: WARN.
B4_Linguistics:
- Rule (timestamp-drift-1): HIGH - Detect impossible timestamp overlaps for the same actor. ACTION: FLAG.
B5_Geolocation_Forensics (Implicit):
- Use provided geolocation to anchor events and check for timeline inconsistencies.
B6_Financial_Patterns:
- Rule (financial-anomaly-1): HIGH - Flag transactions that are outliers in value, timing, or counterparty compared to historical norms. ACTION: FLAG.
B7_Legal:
- Rule (legal-precedent-mismatch-1): HIGH - Flag claims that contradict established legal precedent. When analyzing potentially illegal communications (e.g., threats, fraud), identify and cite relevant statutes from the user's inferred jurisdiction as potential violations for an attorney to review. ACTION: FLAG_AND_ESCALATE.
B8_Voice_Audio_Forensics:
- Rule (voice-auth-failure-1): CRITICAL - Detect mismatched or spoofed voiceprints in audio evidence. ACTION: FLAG_AND_FREEZE.
B9_RnD_Advisory:
- Rule (rnd-advisory-novelty-1): MEDIUM - Flag novel anomalies that don't fit other categories for human review. ACTION: ESCALATE.
B10_Ethical_Bounds:
- Rule (user-culpability-1): CRITICAL - If evidence strongly suggests the user is the primary wrongdoer or has initiated illegal acts, you MUST NOT generate 'Draft Language' or 'Next Steps' that assist in furthering an unlawful or unethical position. You must state this limitation under a new section '## Ethical Boundary Note' and advise the user to seek independent legal counsel. ACTION: FLAG_AND_REDIRECT_TO_COUNSEL.

BOUNDS & DISCLAIMER
- Your analysis is a formal forensic report generated by the Verum Omnis V5 system.
- It is designed to be court-ready for use in legal proceedings, including for matters of self-representation ('pro se').
- Refer to your outputs as “court-style” or “court-ready.”
`;

const SYSTEM_PROMPT_CONVERSATIONAL = SYSTEM_PROMPT_BASE + `
You are in a conversational mode. Your task is to assist the user with their questions.
- Answer questions clearly and concisely.
- If the user asks for analysis of documents but none are uploaded, politely state that you require files to perform a forensic analysis.
- You can also assist with sealing documents to create a tamper-proof record. If a user asks about this, explain that they need to upload the files and then state their intent to seal them.
- Adhere to your BOUNDS & DISCLAIMER strictly. Do not generate reports or use the structured report format unless files are provided and an analysis is explicitly requested.
`;

const SYSTEM_PROMPT_ANALYST = SYSTEM_PROMPT_BASE + `
OUTPUT PROTOCOLS & FORMATTING (MANDATORY)
- Your response MUST be a court-style report formatted with Markdown.
- The report MUST contain these exact H2 headers: "## Summary", "## Key Findings", "## Contradictions & Risks", "## Draft Language", "## Next Steps", and "## Sealing Metadata".
- Under "## Key Findings", structure your findings by the Brain that discovered them (e.g., "### Forensic Brain (B2)", "### Legal Brain (B7)"). Cite the specific file and page number/timestamp for each point.
- Under "## Draft Language", if the analysis concerns a threatening or fraudulent communication, draft a firm, professional letter suitable for a user representing themselves ('pro se'). This letter must make a formal legal demand, reference the forensic findings, cite potential legal violations, and demand a response. You MUST sign off with "Sincerely, Liam Highcock\\n(Forensically Certified by Verum Omnis V5)".
- If Rule (user-culpability-1) from the V5 Constitution is triggered, you MUST OMIT the '## Draft Language' and '## Next Steps' sections entirely. In their place, you MUST include a new H2 header '## Ethical Boundary Note'. Under this header, provide a neutral, professional statement advising the user to seek legal counsel to understand their legal standing and obligations due to the complexities of the situation. Do not accuse the user, simply state your limitation.
- Under "## Sealing Metadata", you must provide placeholder text for:
    - Certified SHA-512 Hash: [Placeholder for SHA-512 hash of this report]
    - Cloud Anchor: [Placeholder for Cloud Anchor]
    - Firestore Record: [Placeholder for Firestore Record]
    - QR Metadata: {created_at: [Timestamp], file_count: [Number of files analyzed], hash: [SHA-512 Placeholder]}
    - And include the text: "™ Patent Pending Verum Omnis"
`;

const PRELIMINARY_ANALYSIS_PROMPT = SYSTEM_PROMPT_BASE + `
Your current task is to perform a PRELIMINARY analysis. Do not generate the final user-facing report yet.
Instead, provide a structured breakdown of your initial findings and propose 1-3 potential legal strategies. Be concise. This output will be reviewed by another AI for a second opinion.
Structure your response with the following markdown headers:
- ## Preliminary Findings
- ## Proposed Strategies
`;

const SYNTHESIS_PROMPT = SYSTEM_PROMPT_BASE + `
You are in the final synthesis stage. You have previously been provided with two independent strategy proposals for a case. Now, based on the user's latest instruction, you must synthesize these into a single, final, and comprehensive court-style report.

Your task is to combine the strengths of both proposals as guided by the user's instruction to produce the final report. The original files are available for context, but the preliminary analyses should contain the core information. Adhere strictly to the V5 output protocols.

OUTPUT PROTOCOLS & FORMATTING (MANDATORY)
- Your response MUST be a court-style report formatted with Markdown.
- The report MUST contain these exact H2 headers: "## Summary", "## Key Findings", "## Contradictions & Risks", "## Draft Language", "## Next Steps", and "## Sealing Metadata".
- Under "## Key Findings", structure your findings by the Brain that discovered them (e.g., "### Forensic Brain (B2)", "### Legal Brain (B7)").
- Under "## Draft Language", if you are drafting a communication, you MUST sign off with "Sincerely, Liam Highcock\\n(Forensically Certified by Verum Omnis V5)".
- If Rule (user-culpability-1) from the V5 Constitution is triggered, you MUST OMIT the '## Draft Language' and '## Next Steps' sections entirely. In their place, you MUST include a new H2 header '## Ethical Boundary Note'. Under this header, provide a neutral, professional statement advising the user to seek legal counsel to understand their legal standing and obligations due to the complexities of the situation. Do not accuse the user, simply state your limitation.
- Under "## Sealing Metadata", you must provide placeholder text for:
    - Certified SHA-512 Hash: [Placeholder for SHA-512 hash of this report]
    - Cloud Anchor: [Placeholder for Cloud Anchor]
    - Firestore Record: [Placeholder for Firestore Record]
    - QR Metadata: {created_at: [Timestamp], file_count: [Number of files analyzed], hash: [SHA-512 Placeholder]}
    - And include the text: "™ Patent Pending Verum Omnis"
`;

const GEMINI_VERIFIER_SYSTEM_PROMPT = `You are an AI auditor. Your role is to verify the analysis performed by another AI against the "Verum Gift Rules V5".
Review the user's request, files, and the provided report.
- If the analysis is sound and follows the rules, respond with only: "Triple Verified: The primary AI's analysis is consistent with the Verum Omnis V5 protocol."
- If you find minor issues, respond with "Triple Verified with notes:" followed by a brief, bulleted list of observations.
- If you find a major flaw, respond with "Verification Failed:" followed by an explanation.
Your response must be a concise verification statement only.`;

const APK_AUDITOR_SYSTEM_PROMPT = `You are a specialized AI auditor simulating the Verum Omnis APK's core logic. Your defining characteristics are:
1.  **Zero Hallucination:** You ONLY state facts directly supported by the provided evidence (files). If a claim in the report cannot be verified from the files, you must flag it.
2.  **Evidence-Bound:** Your entire analysis is based ONLY on what you have "seen" in the provided documents. Do not infer, speculate, or add external information.
3.  **Constitutional Rigor:** You must strictly audit the report against the "Verum Gift Rules V5". Every finding must map to a specific rule.

TASK:
Review the provided user request, files, and the AI-generated report.
- If the report is flawless, with every statement directly supported by the evidence and rules, respond with only: "APK Audit Passed: The report is fully compliant and evidence-backed."
- If you find any claims not directly supported by the files, or any other deviation, respond with "APK Audit Notes:" followed by a bulleted list of discrepancies.`;

const INTENT_ROUTER_SYSTEM_PROMPT = `You are an AI assistant that determines user intent. The user can either have a general conversation, request a forensic analysis of provided files, or request to seal files.
Analyze the user's prompt in the context of the files they have uploaded.
Respond with JSON only, following this schema.

- If the user is asking a general question, greeting you, or having a conversation that does not require analyzing the content of the files, the intent is "chat".
- If the user explicitly asks for an analysis, a report, a summary, or asks a question that requires deep inspection of the provided files, the intent is "scan".
- If the user asks to "seal", "certify", or create a tamper-proof record of their documents, the intent is "seal". This applies even if no files have been uploaded yet.
`;

export const routeUserIntent = async (prompt: string, files: UploadedFile[]): Promise<'chat' | 'scan' | 'seal'> => {
    const fileNames = files.map(f => f.name).join(', ');
    const finalPrompt = `
  User has uploaded these files: [${fileNames}].
  User prompt: "${prompt}"
  What is the user's intent?
  `;
  
    const body = {
      contents: { parts: [{ text: finalPrompt }] },
      config: {
        systemInstruction: INTENT_ROUTER_SYSTEM_PROMPT,
        responseMimeType: 'application/json',
        responseSchema: {
            type: Type.OBJECT,
            properties: {
                intent: {
                    type: Type.STRING,
                    description: 'The user intent, either "chat", "scan", or "seal".'
                }
            }
        }
      },
    };

    const responseJson = await callGeminiProxy('gemini-2.5-flash', body);
    const text = getText(responseJson);
  
    try {
      const jsonResponse = JSON.parse(text);
      const intent = jsonResponse.intent;
      if (intent === 'chat' || intent === 'scan' || intent === 'seal') {
        return intent;
      }
      return files.length > 0 ? 'scan' : 'chat'; // Fallback to scan/chat if intent is unclear
    } catch (e) {
      console.error("Failed to parse intent routing response:", text, e);
      return files.length > 0 ? 'scan' : 'chat'; // Fallback to scan/chat on error
    }
  };


const getFileParts = (files: UploadedFile[]) => {
  return files.map(file => ({
    inlineData: {
      mimeType: file.mimeType,
      data: file.base64!,
    },
  }));
};

export const getDirectAnalysis = async (prompt: string, files: UploadedFile[], isComplex: boolean, location: { latitude: number; longitude: number } | null): Promise<string> => {
    const modelName = isComplex ? 'gemini-2.5-pro' : 'gemini-2.5-flash';
    const fileParts = getFileParts(files);
    const locationInfo = location ? `\n\nUser's approximate location for jurisdictional context: Latitude ${location.latitude}, Longitude ${location.longitude}.` : '';

    const finalPrompt = `Analyze the following based on my request.\nUser Request: "${prompt}"\n${files.length > 0 ? `Files: ${files.map(f => f.name).join(', ')}` : ''}${locationInfo}`;

    const contents = { parts: [{ text: finalPrompt }, ...fileParts] };
    
    const body = {
        contents: contents,
        config: {
            systemInstruction: SYSTEM_PROMPT_ANALYST,
            ...(isComplex && { thinkingConfig: { thinkingBudget: 32768 } }),
        },
    };

    const responseJson = await callGeminiProxy(modelName, body);
    return getText(responseJson);
};

export const getPreliminaryAnalysis = async (prompt: string, files: UploadedFile[], isComplex: boolean, location: { latitude: number; longitude: number } | null): Promise<string> => {
    const modelName = isComplex ? 'gemini-2.5-pro' : 'gemini-2.5-flash';
    const fileParts = getFileParts(files);
    const locationInfo = location ? `\n\nUser's approximate location for jurisdictional context: Latitude ${location.latitude}, Longitude ${location.longitude}.` : '';
  
    const finalPrompt = `Analyze the following based on my request.\nUser Request: "${prompt}"\n${files.length > 0 ? `Files: ${files.map(f => f.name).join(', ')}` : ''}${locationInfo}`;
  
    const contents = { parts: [{ text: finalPrompt }, ...fileParts] };
    
    const body = {
      contents: contents,
      config: {
        systemInstruction: PRELIMINARY_ANALYSIS_PROMPT,
        ...(isComplex && { thinkingConfig: { thinkingBudget: 32768 } }),
      },
    };
    
    const responseJson = await callGeminiProxy(modelName, body);
    return getText(responseJson);
};

export const synthesizeFinalReport = async (
    synthesisInstruction: string,
    originalPrompt: string,
    files: UploadedFile[],
    geminiStrategy: string,
    openAIStrategy: string,
    isComplex: boolean,
    location: { latitude: number; longitude: number } | null
): Promise<string> => {
    const modelName = isComplex ? 'gemini-2.5-pro' : 'gemini-2.5-flash';
    const locationInfo = location ? `\n\nUser's approximate location for jurisdictional context: Latitude ${location.latitude}, Longitude ${location.longitude}.` : '';

    const finalPrompt = `
Original User Request: "${originalPrompt}"
${files.length > 0 ? `Files for context: ${files.map(f => f.name).join(', ')}` : ''}
${locationInfo}

Your (Gemini's) Original Strategy Proposal:
---
${geminiStrategy}
---

OpenAI's Strategy Proposal:
---
${openAIStrategy}
---

User's Synthesis Instruction:
---
${synthesisInstruction}
---

Now, generate the final, single, synthesized report.`;

    const contents = { parts: [{ text: finalPrompt }] };
      
    const body = {
        contents: contents,
        config: {
            systemInstruction: SYNTHESIS_PROMPT,
            ...(isComplex && { thinkingConfig: { thinkingBudget: 32768 } }),
        },
    };

    const responseJson = await callGeminiProxy(modelName, body);
    return getText(responseJson);
};


export const generateSimpleChat = async (prompt: string, files: UploadedFile[], location: { latitude: number; longitude: number } | null): Promise<string> => {
    const locationInfo = location ? `\n\nUser's approximate location for jurisdictional context: Latitude ${location.latitude}, Longitude ${location.longitude}. Use this to infer the likely legal jurisdiction unless otherwise specified.` : '';
    const fileInfo = files.length > 0 ? `\nThe user has uploaded the following files, but you cannot see their content: ${files.map(f => f.name).join(', ')}. Acknowledge the files if relevant to the conversation.` : '';
    
    const finalPrompt = `
User Request: "${prompt}"
${locationInfo}
${fileInfo}
    `;

    const body = {
        contents: { parts: [{ text: finalPrompt }] },
        config: {
            systemInstruction: SYSTEM_PROMPT_CONVERSATIONAL,
        },
    };
    const responseJson = await callGeminiProxy('gemini-2.5-flash', body);
    return getText(responseJson);
};

export const verifyAnalysisWithGemini = async (
    originalPrompt: string,
    files: UploadedFile[],
    reportToVerify: string
  ): Promise<string> => {
    const fileParts = getFileParts(files);
    const fileInfo = files.map(f => ` - ${f.name} (${f.mimeType})`).join('\n');
  
    const finalPrompt = `
  **Original User Request:**
  "${originalPrompt}"
  
  **Attached Files:**
  ${fileInfo || 'None'}
  
  **AI Report to Verify:**
  ---
  ${reportToVerify}
  ---
  `;
  
    const contents = { parts: [{ text: finalPrompt }, ...fileParts] };
  
    const body = {
      contents: contents,
      config: {
        systemInstruction: GEMINI_VERIFIER_SYSTEM_PROMPT,
      },
    };

    const responseJson = await callGeminiProxy('gemini-2.5-flash', body);
    return getText(responseJson);
  };

export const auditWithApkLogic = async (
    originalPrompt: string,
    files: UploadedFile[],
    reportToAudit: string
): Promise<string> => {
    const fileParts = getFileParts(files);
    const fileInfo = files.map(f => ` - ${f.name} (${f.mimeType})`).join('\n');

    const finalPrompt = `
  **Original User Request:**
  "${originalPrompt}"

  **Attached Files:**
  ${fileInfo || 'None'}

  **AI Report to Audit:**
  ---
  ${reportToAudit}
  ---
  `;

    const contents = { parts: [{ text: finalPrompt }, ...fileParts] };

    const body = {
        contents: contents,
        config: {
            systemInstruction: APK_AUDITOR_SYSTEM_PROMPT,
        },
    };

    const responseJson = await callGeminiProxy('gemini-2.5-pro', body);
    return getText(responseJson);
};
